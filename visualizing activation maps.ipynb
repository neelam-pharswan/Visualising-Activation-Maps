{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d31b0ee-a49c-4821-8190-8dd959f6d14c",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'E:\\\\Emotions\\\\Test\\\\Happy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotion_detection_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m      8\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEmotions\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mHappy\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[1;32m----> 9\u001b[0m img \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mload_img(img_path, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m))  \n\u001b[0;32m     10\u001b[0m img_array \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(img)\n\u001b[0;32m     11\u001b[0m img_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_array, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\image_utils.py:235\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[0;32m    234\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    236\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'E:\\\\Emotions\\\\Test\\\\Happy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = load_model('emotion_detection_model.keras') \n",
    "\n",
    "img_path = r'E:\\Emotions\\Test\\Happy' \n",
    "img = image.load_img(img_path, target_size=(224, 224))  \n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.0 \n",
    "\n",
    "# 3. Get the intermediate layer to visualize activation maps\n",
    "layer_name = 'conv2d_2'  \n",
    "intermediate_layer_model = Model(inputs=model.input, outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(img_array)\n",
    "\n",
    "# 4. Visualize the activation maps\n",
    "num_filters = intermediate_output.shape[-1]  # Number of filters in the layer\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(num_filters):\n",
    "    plt.subplot(8, 8, i + 1)  # Arrange subplots for multiple filters\n",
    "    plt.imshow(intermediate_output[0, :, :, i], cmap='viridis')  # Use a colormap like 'viridis'\n",
    "    plt.axis('off')  # Turn off axes for clarity\n",
    "plt.show()\n",
    "\n",
    "# Optional: Overlay activation map on the original image\n",
    "# Choose a filter index to visualize the activations overlaid on the input image\n",
    "filter_index = 0  # Choose the filter index you want to visualize\n",
    "\n",
    "# Get the activation map for that filter\n",
    "activation_map = intermediate_output[0, :, :, filter_index]\n",
    "\n",
    "# Normalize the activation map\n",
    "activation_map -= activation_map.min()\n",
    "activation_map /= activation_map.max()\n",
    "\n",
    "# Resize activation map to match the input image size for overlay\n",
    "activation_map_resized = np.uint8(np.resize(activation_map, (224, 224)) * 255)\n",
    "\n",
    "# Plot original image with the activation map overlay\n",
    "plt.imshow(img)\n",
    "plt.imshow(activation_map_resized, cmap='jet', alpha=0.5)  # Overlay activation map with transparency\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d20c9-f586-4bbf-8b9d-0f056470274a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726bd7e4-19e4-4be1-8912-0cee095aa8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
